# Netbalance:

A Systematic Evaluation Framework For Fair Assessment of Association Prediction Models

## âš™ï¸ Installation
1. Clone the Repository and Enter the Project Directory:
    ```bash
    git clone https://github.com/sobhanAhmadian/netbalance.git
    cd netbalance
    ```
2. Ensure Correct Python Version
    - Required: >=3.12,<3.13
    - We recommend using a tool like [pyenv](https://github.com/pyenv/pyenv) to manage Python versions.
        ```bash
        pyenv install 3.12
        pyenv local 3.12
        ```
3. We use [Poetry](https://python-poetry.org/) for dependency management. 
    - [Install Poetry](https://python-poetry.org/docs/#installing-with-the-official-installer) if you haven't already.
    - Configure Poetry to Create Virtual Environment Inside Project Folder (Optional)
        ```bash
        poetry config virtualenvs.in-project true
        ```
4. Create a Virtual Environment and Install Dependencies
    ```bash
    poetry install
    ```
5. Activate the Virtual Environment
    ```bash
    eval $(poetry env activate)
    ```
6. Install Pytorch Manually
    - We do not list PyTorch in pyproject.toml because the package is OS-dependent. [Install PyTorch 2.6.0](https://pytorch.org/get-started/previous-versions/#:~:text=v2.6.0) manually after activating the environment.

## ðŸ“¥ Data Preparation
The datasets used in this project are not included in the repository due to their size. Please follow the instructions below to download and prepare the data.

- Download the raw and processed data files from the [here](https://doi.org/10.6084/m9.figshare.30122011.v1).
- Unzip the downloaded file and place the `data_repository` folder in the `src/netbalance/data_repository/` path.

## ðŸ“– Tutorials  

We provide a set of Jupyter notebooks demonstrating how to use this project, reproduce results, and explore the methodology step-by-step. You can find them in the [`examples/`](./examples) directory.

| Notebook | Description |
|----------|-------------|
| [`association_data.ipynb`](./examples/association_data.ipynb) | How to create an association data object, apply different data balancing methodologies, and visualize the results. |
| [`evaluation_framework.ipynb`](./examples/evaluation_framework.ipynb) | How to use netbalnce's evaluation framework to assess the performance of an arbitrary association prediction model on an arbitrary association data. |

## ðŸ“š Terminology

The terminology used in this project slightly differs from that in the paper. Below is a brief explanation of the terms used here.

### Evaluation Framework Terminology

| Term | Description |
|------|-------------|
| beta | Equivalent to the term â€œbalancedâ€ used in the paper, it refers to employing a balanced dataset, which can be utilized for either training or testing a model. |
| eta | Equivalent to the term â€œfull testâ€ in the paper, it denotes using the entire dataset. |
| rho | Equivalent to the term â€œentity-balancedâ€ in the paper, it refers to using a entity-balanced dataset. |
| ibeta | In training, it refers to using balanced data in an iterative manner. |
| irho | In training, it refers to using entity-balanced data in an iterative manner. |

### Model Terminology
| Term | Description |
|------|-------------|
| blindti | Stands for "Base line model - Linear - Drug Target Interaction dataset". It's our linear benchmark model for the drug-target interaction dataset. |
| blinsyn | Stands for "Base line model - Linear - drug SYNergy dataset". It's our linear benchmark model for the drug synergy dataset. |
| bmlpdti | Stands for "Base line model - MLP - Drug Target Interaction dataset". It's our MLP benchmark model for the drug-target interaction dataset. |
| bmlpsyn | Stands for "Base line model - MLP - drug SYNergy dataset". It's our MLP benchmark model for the drug synergy dataset. |
| brfdti | Stands for "Base line model - Random Forest - Drug Target Interaction dataset". It's our random forest benchmark model for the drug-target interaction dataset. |
| brfsyn | Stands for "Base line model - Random Forest - drug SYNergy dataset". It's our random forest benchmark model for the drug synergy dataset. |
| bxgbdti | Stands for "Base line model - XGBoost - Drug Target Interaction dataset". It's our XGBoost benchmark model for the drug-target interaction dataset. |
| bxgbsyn | Stands for "Base line model - XGBoost - drug SYNergy dataset". It's our XGBoost benchmark model for the drug synergy dataset. |

## ðŸ“‚ Project Structure
```bash
netbalance/
â”œâ”€â”€ examples/                 
â”œâ”€â”€ src/                      
â”‚   â”œâ”€â”€ netbalance/           
â”‚   â”‚   â”œâ”€â”€ __init__.py 
â”‚   â”‚   â”œâ”€â”€ configs/          # Configuration definitions
â”‚   â”‚   â”œâ”€â”€ data_repository/  # Repository for data files
â”‚   â”‚   â”œâ”€â”€ data/             # Data handling
â”‚   â”‚   â”œâ”€â”€ evaluation/       # Evaluation functions
â”‚   â”‚   â”œâ”€â”€ features/         # Dataset definitions
â”‚   â”‚   â”œâ”€â”€ jobs/             # End-point python scripts
â”‚   â”‚   â”œâ”€â”€ methods/          # Algorithms and methods
â”‚   â”‚   â”œâ”€â”€ models/           # Model definitions
â”‚   â”‚   â”œâ”€â”€ optimization/     # Trainer definitions
â”‚   â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â”‚   â””â”€â”€ visualization/    # Visualization functions
â”œâ”€â”€ .env.example    # Example environment variables file
â”œâ”€â”€ .gitignore      # Git ignore file
â”œâ”€â”€ LICENSE         # License file
â”œâ”€â”€ poetry.lock     # Poetry lock file
â”œâ”€â”€ pyproject.toml  # Poetry project file
â””â”€â”€ README.md       # Project documentation
```

### ðŸ“‚ Jobs Directory

The python scripts in the `jobs` directory are designed to be run as standalone scripts. It contains two main directories:

- `data_analysis`: Contains scripts for the dataset analysis.
- `model_evaluation`: This directory contains scripts for running evaluation frameworks on different models. It is organized into two subdirectories:
  - `calculations`: Stage 1 of the evaluation framework, as discribed in the tutorials.
  - `results`: Stage 2 of the evaluation framework, as discribed in the tutorials.

Both `calculations` and `results` are first organized by dataset, and then by training methodology. The `results` directory is further subdivided by evaluation frameworkâ€”such as `beta`, `eta`, and `rho`. Finally, each of these subdirectories contains scripts for different models.

### Random Forest Model Example

For example, the files for the **Random Forest model** on the **Sanger** dataset are located at:

+ Dataset Part

    | description | path |
    |-------------|------|
    | Sanger dataset Conigs | [`src/netbalance/configs/sanger.py`](./src/netbalance/configs/sanger.py) |
    | Sanger dataset Handler | [`src/netbalance/features/sanger.py`](./src/netbalance/features/sanger.py) |

+ Model Part
    | description | path |
    |-------------|------|
    | Model and Optimizer Configs | [`src/netbalance/configs/brfsyn.py`](./src/netbalance/configs/brfsyn.py) |
    | Model Defenition | [`src/netbalance/models/brfsyn.py`](./src/netbalance/models/brfsyn.py) |
    | Trainer Definition | [`src/netbalance/optimization/brfsyn.py`](./src/netbalance/optimization/brfsyn.py) |
+ Evaluation Part
    | description | path |
    |-------------|------|
    | Stage 1 | [`src/netbalance/jobs/model_evaluation/calculations/sanger/beta/brfsyn.py`](./src/netbalance/jobs/model_evaluation/calculations/sanger/beta/brfsyn.py) |
    | Stage 2 - Full Test Evaluation | [`src/netbalance/jobs/model_evaluation/results/sanger/beta/eta/brfsyn.py`](./src/netbalance/jobs/model_evaluation/results/sanger/beta/eta/brfsyn.py) |
    | Stage 2 - Balanced Evaluation | [`src/netbalance/jobs/model_evaluation/results/sanger/beta/beta/brfsyn.py`](./src/netbalance/jobs/model_evaluation/results/sanger/beta/beta/brfsyn.py) |
    | Stage 2 - Entity-balanced Evaluation | [`src/netbalance/jobs/model_evaluation/results/sanger/beta/rho/brfsyn.py`](./src/netbalance/jobs/model_evaluation/results/sanger/beta/rho/brfsyn.py) |